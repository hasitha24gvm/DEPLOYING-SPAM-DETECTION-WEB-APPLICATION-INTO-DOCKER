{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam_detector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbp8cFhFlYXr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-SwjP0-6lmLT",
        "outputId": "873c4d97-ee33-4ddb-8206-07f42aeba536"
      },
      "source": [
        "data = pd.read_csv('spam_data.csv')\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4pkoofimGur"
      },
      "source": [
        "# ***PROCESSING THE TEXT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUcUcEjOlwd1"
      },
      "source": [
        "import re\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
        "    return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yfNGdiGmPRY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = data['Message'].apply(preprocessor)\n",
        "y = data['Category']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9lXGRYHmcHY"
      },
      "source": [
        "# ***Training with Neural Network Pipeline***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THQA9P3Vmo-G",
        "outputId": "08983222-ef02-4670-bfc3-fe37f16e70d2"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Encoding the text data\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, max_features=700, ngram_range=(1,1))\n",
        "\n",
        "neural_net_pipeline = Pipeline([('vectorizer', tfidf), \n",
        "                                ('nn', MLPClassifier(hidden_layer_sizes=(700, 700)))])\n",
        "\n",
        "neural_net_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=False, max_df=1.0, max_features=700,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...\n",
              "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
              "                               early_stopping=False, epsilon=1e-08,\n",
              "                               hidden_layer_sizes=(700, 700),\n",
              "                               learning_rate='constant',\n",
              "                               learning_rate_init=0.001, max_fun=15000,\n",
              "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "                               nesterovs_momentum=True, power_t=0.5,\n",
              "                               random_state=None, shuffle=True, solver='adam',\n",
              "                               tol=0.0001, validation_fraction=0.1,\n",
              "                               verbose=False, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-m1XkUwnOS_",
        "outputId": "85c4c4be-c767-479f-cdba-807e28a0ad73"
      },
      "source": [
        "#Testing the NN-pipeline\n",
        "y_pred = neural_net_pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy: {} %'.format(100 * accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99      1448\n",
            "        spam       0.96      0.92      0.94       224\n",
            "\n",
            "    accuracy                           0.99      1672\n",
            "   macro avg       0.98      0.96      0.97      1672\n",
            "weighted avg       0.98      0.99      0.98      1672\n",
            "\n",
            "Accuracy: 98.50478468899522 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQVikD2rngJx",
        "outputId": "5dc541f9-0edf-45d3-dd00-9be74d7f899c"
      },
      "source": [
        "#Saving the pipeline using joblib\n",
        "from joblib import dump\n",
        "dump(neural_net_pipeline, 'spam_classifier.joblib')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spam_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}